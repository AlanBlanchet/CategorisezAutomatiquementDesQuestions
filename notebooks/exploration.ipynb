{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "\n",
    "Dans cette partie on va donc explorer nos données afin de se familiariser avec le dataset.\n",
    "\n",
    "Pour cette exploration j'utilise une variable `version` qui me permet d'avoir le même résultat par rapport à la version du script que je souhaite utiliser.\n",
    "\n",
    "En interne certaines actions sont effectuées sur le dataset suivant la version. Cela me permet de montrer ma démarche et la progression des traitements / explorations du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(['ggplot', 'https://raw.githubusercontent.com/AlanBlanchet/matplotlib_styles/master/vscode_blue.mplstyle'])\n",
    "\n",
    "Dataset.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire une cellule de comparaison pour avoir un affichage des données brutes et des données traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.example(\"topics1.csv\", random_state=0, version=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons les mots les plus communs et identifions les mots inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Dataset.most_common(\"commons_v0\", version=1)\n",
    "freq.most_common(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque dors et déjà qu'on a des ponctuations.\n",
    "\n",
    "J'ai bien envie de faire un système pour pouvoir voir les phrases en brute et les voir en preprocessé pour voir la différence et comprendre certains cas. On peut donc retirer ces ponctuations puis regarder quelques examples qui nous permettrons d'avancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Dataset.most_common(\"commons_v0\", version=2)\n",
    "freq.most_common(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque déjà qu'il y a le \"n't\" qui correspond à une négation.\n",
    "\n",
    "Il y a également des mots qu'on aimerait certainement exclure car il n'apporte par de plus value pour nos prédictions de tags comme par exemple : \"problem\", \"error\", \"get\", \"code\", \"like\"...\n",
    "\n",
    "Pour régler le problème de la négation, je me suis d'abord dit qu'il serait bien de supprimer les chaînes qui ont une longueur égale à 1. Mais rappelons un instant que le langage C comporte 1 seul caractère. Il n'est donc pas possible de procéder comme cela. On aimerait possiblement conserver la négation car cela pourrait être utile pour une phrase du genre : \"this is not Java\". On gardera dans un premier temps cette négation.\n",
    "\n",
    "Pour les mots qu'on aimerait exclure, je propose de mettre ces mots dans un fichier texte. Ils feront office de \"stopwords\" propres au projet. (dans data/exclude.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.example(\"topics1.csv\", random_state=0, version=1, interactive=True, index=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc tous les outils en main pour commencer à effectuer des analyses plus poussées et effectuer des tests sur nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Dataset.use(\"topics1.csv\", version=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sententences_l = df.text.str.len().sort_values()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Text indece by their lengths\")\n",
    "plt.xlabel(\"Text indice\")\n",
    "plt.ylabel(\"Text length\")\n",
    "sententences_l.reset_index(drop=True).plot()\n",
    "sententences_l.describe(percentiles=[0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que quelques phrases sont très longues (2.5% avec l > 6992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = df.target.str.split(\"|\").explode()\n",
    "print(len(target_list.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_counts = target_list.value_counts().sort_values()\n",
    "target_list_counts_tail = target_list_counts.tail(30)\n",
    "target_list_counts_tail.plot.barh()\n",
    "plt.title(\"Top 30 most commonly used tags in the dataset\")\n",
    "plt.xlabel(\"Counts\")\n",
    "plt.ylabel(\"Targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_count_under_5 = target_list_counts[target_list_counts < 5]\n",
    "target_list_count_under_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains targets ne seront certainement pas simple à trouver car seulement 5000 ont une fréquence de 5 ou +. On peut donc se demander si conserver autant d'éléments est utile. On verra par la suite ce que l'on fait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_over_5 = target_list[~target_list.isin(target_list_count_under_5.index)]\n",
    "target_list_over_5_target_count = pd.Series(target_list_over_5.index.value_counts()).value_counts()\n",
    "target_list_over_5_target_count[0] = len(df) - target_list_over_5_target_count.sum()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Leftover targets number per text\\nafter removing low frequency targets (< 5)\")\n",
    "plt.yscale('log')\n",
    "target_list_over_5_target_count.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Number of leftovers\")\n",
    "plt.ylabel(\"Number of texts\")\n",
    "target_list_over_5_target_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, si on retirait ces targets, 12 lignes n'auraient plus de target du tout."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing avancé\n",
    "\n",
    "Dans cette partie on va regarder un peu plus notre dataset pour trouver des éléments mal preprocessé et noter l'index des phrases où l'on trouve ces cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.example(\"topics1.csv\", random_state=0, version=2, interactive=True, index=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les élément que nous devons maintenant traiter ainsi que l'index des phrases où le problème a été repéré :\n",
    "\n",
    "- Les nombres (2, 14)\n",
    "- Le \"#\" de C# est coupé (6)\n",
    "- Attention à ne pas supprimer délaisser des nombres importants comme 64 (8)\n",
    "- Dates peuvent être importantes (8)\n",
    "- Le \"++\" de C++ est coupé (10,30)\n",
    "- Il y a des urls (12,19,26,34,35,52,54)\n",
    "- Des morceaux de code sans block de code (12,13,26,27,52,500)\n",
    "- On supprime les balises \"code\" ce qui a pour effet de laisser certains textes un peu trop vide (14,19,20)\n",
    "\n",
    "Constats :\n",
    "- Certains éléments sont très compliqués à tagger même pour un être humain (9,11,500)\n",
    "- La négation est importants dans certains contextes (10)\n",
    "- Certains tags seront quasiement introuvable pour certaines situations. Il faudra habilement choisir une fonction de score (tous les exemples)\n",
    "\n",
    "\n",
    "## Actions\n",
    "\n",
    "- Retirer les URLs car ils vont brouiller la target (ex: \"http\", \"https\", \"www\" ...)\n",
    "- Laisser les nombres car ils peuvent avoir une importance\n",
    "- Retirer \n",
    "\n",
    "En effet, peut être que\n",
    "- Le découpage d'un URL peut donner une indication.\n",
    "- Les nombres sont importants\n",
    "\n",
    "Il faut néanmoins corrigé certains autres problèmes dans l'immédiat comme celui du C++/C#.\n",
    "\n",
    "Pour ce qui est de prendre en compte le contexte (négation) on verra par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\"#\", \"+\"]\n",
    "np.array([target for target in set(target_list)\n",
    " if pd.Series(chars).isin(list(target)).any()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que beaucoup de targets ont des version (ex: \"c++-32\") associées à leur nom. J'ai bien peur que le fait que la version soit présente brouille la prédiction.\n",
    "\n",
    "On se rappellera d'un possible traitement à effectuer par la suite. Je suppose naivement que l'on ne souhaite pas forcément prédire la version spécifique en fonction d'une question mais plutôt juste le tag initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.example(\"topics1.csv\", random_state=0, version=3, interactive=True, index=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.example(\"topics1.csv\", random_state=0, version=4, interactive=True, index=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine étape serait de s'intéresser à la balise code afin de rajouter de l'information.\n",
    "En effet, comme on l'a vu précédemment, certaines questions on vu la majorité de contenu se faire supprimer car la majorité était du code.\n",
    "\n",
    "On peut commencer par essayer, en fonction de la balise de code, de détecter le language qui y est présent.\n",
    "\n",
    "Après expérimentation avec les packages [guesslang](https://github.com/yoeo/guesslang) / [whats_that_code](https://github.com/matthewdeanmartin/whats_that_code) c'était très difficile. Le seule package qui m'apporte un peu d'espoir est [pygments](https://github.com/pygments/pygments) mais il a parfois de mauvaises prédictions.\n",
    "\n",
    "Je propose malgré tout de l'utiliser et de voir ce que cela donne.\n",
    "\n",
    "On va donc simplement remplacer la balise de code par le nom du langage détecté pour chaque morceaux de code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.example(\"topics1.csv\", random_state=0, version=4, interactive=True, index=14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après ce que je vois, ce n'est pas fameux. On pourra revenir sur cette partie plus tard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
