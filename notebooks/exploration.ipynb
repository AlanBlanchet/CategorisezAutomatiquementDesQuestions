{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "\n",
    "Dans cette partie on va donc explorer nos données afin de se familiariser avec le dataset.\n",
    "\n",
    "Pour cette exploration j'avais au départ utilisé un attribut `version` qui me permettait d'avoir le même résultat par rapport à la version du script que je souhaite utiliser. Mais j'ai changé d'avis car je commençais à avoir trop de blocks \"if\" pour checker la version du code à utiliser.\n",
    "\n",
    "En interne certaines actions étaient donc effectuées sur le dataset suivant la version. Cela me permettait de montrer ma démarche et la progression des traitements / explorations du dataset. Néanmoins maintenant je vais donc montrer les changements au fur et à mesure du notebook.\n",
    "\n",
    "Je montre donc à travers les champs `markdown` les moments où j'ai testé des fonctions. J'ai ensuite implémenté ces fonctions dans mon script python `src/dataset/dataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(['ggplot', 'https://raw.githubusercontent.com/AlanBlanchet/matplotlib_styles/master/vscode_blue.mplstyle'])\n",
    "\n",
    "Dataset.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire une cellule de comparaison pour avoir un affichage des données brutes et des données traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = Dataset(\"topics1.csv\")\n",
    "topics.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.df[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.example(interactive=False, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'avais donc au départ effectué plusieurs opération avec un système de version. Voici ce qui avait été fait :\n",
    "\n",
    "- Remarquer les poncutation et les traiter\n",
    "- Mise en place d'un système pour voir des examples (comme ci-dessus) mais de manière intéractive\n",
    "- Remarquer la négation \"n't\" qui est présente\n",
    "- Des mots qu'on aimerait peut être exclure car il n'apporte pas de plus value pour nos prédictions de tags comme par exemple : \"problem\", \"error\", \"get\", \"code\", \"like\"...\n",
    "    - Pour régler le problème de la négation, je me suis d'abord dit qu'il serait bien de supprimer les chaînes qui ont une longueur égale à 1. Mais rappelons un instant que le langage C comporte 1 seul caractère. Il n'est donc pas possible de procéder comme cela. On aimerait possiblement conserver la négation car cela pourrait être utile pour une phrase du genre : \"this is not Java\". On gardera dans un premier temps cette négation.\n",
    "    - Pour les mots qu'on aimerait exclure, je propose de mettre ces mots dans un fichier texte. Ils feront office de \"stopwords\" propres au projet (dans data/exclude.txt). On fera ce traitement si besoin par la suite "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons les mots les plus communs et identifions les mots inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.example(index=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc tous les outils en main pour commencer à effectuer des analyses plus poussées et effectuer des tests sur nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sententences_l = topics.df[\"text\"].str.len().sort_values()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Text indece by their lengths\")\n",
    "plt.xlabel(\"Text indice\")\n",
    "plt.ylabel(\"Text length\")\n",
    "sententences_l.reset_index(drop=True).plot()\n",
    "sententences_l.describe(percentiles=[0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que quelques phrases sont très longues (2.5% avec l > 6992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = topics.df[topics.targets].stack().reset_index().drop(columns=\"level_1\").set_index(\"level_0\")\n",
    "target_list = target_list[0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_counts = target_list.value_counts().sort_values()\n",
    "target_list_counts_tail = target_list_counts.tail(30)\n",
    "target_list_counts_tail.plot.barh()\n",
    "plt.title(\"Top 30 most commonly used tags in the dataset\")\n",
    "plt.xlabel(\"Counts\")\n",
    "plt.ylabel(\"Targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_count_under_5 = target_list_counts[target_list_counts < 5]\n",
    "target_list_count_under_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains targets ne seront certainement pas simple à trouver car seulement 5000 ont une fréquence de 5 ou +. On peut donc se demander si conserver autant d'éléments est utile. On verra par la suite ce que l'on fait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_over_5 = target_list[~target_list.isin(target_list_count_under_5.index)]\n",
    "target_list_over_5_index_counts = cudf.Series(target_list_over_5.index).value_counts()\n",
    "target_list_over_5_target_count = target_list_over_5_index_counts.value_counts()\n",
    "target_list_over_5_target_count[0] = len(topics.df) - target_list_over_5_target_count.sum()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Leftover targets number per text\\nafter removing low frequency targets (< 5)\")\n",
    "plt.yscale('log')\n",
    "target_list_over_5_target_count.to_pandas().plot(kind=\"bar\")\n",
    "plt.xlabel(\"Number of leftovers\")\n",
    "plt.ylabel(\"Number of texts\")\n",
    "target_list_over_5_target_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, si on retirait ces targets, 7 lignes n'auraient plus de target du tout."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing avancé\n",
    "\n",
    "## Itération 1\n",
    "\n",
    "Dans cette partie on va regarder un peu plus notre dataset pour trouver des éléments mal preprocessé et noter l'index des phrases où l'on trouve ces cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.example(index=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai effectué ce traitement sur mon dataset local qui, en plus, a changé entre temps. Ce qui compte malgré tout sont les problèmes que j'ai pu y repérer\n",
    "\n",
    "Voici donc les élément que nous devons maintenant traiter ainsi que l'index des phrases où le problème a été repéré :\n",
    "\n",
    "- Les nombres (2, 14)\n",
    "- Le \"#\" de C# est coupé (6)\n",
    "- Attention à ne pas supprimer délaisser des nombres importants comme 64 (8)\n",
    "- Dates peuvent être importantes (8)\n",
    "- Le \"++\" de C++ est coupé (10,30)\n",
    "- Il y a des urls (12,19,26,34,35,52,54)\n",
    "- Des morceaux de code sans block de code (12,13,26,27,52,500)\n",
    "- On supprime les balises \"code\" ce qui a pour effet de laisser certains textes un peu trop vide (14,19,20)\n",
    "\n",
    "Constats :\n",
    "- Certains éléments sont très compliqués à tagger même pour un être humain (9,11,500)\n",
    "- La négation est importants dans certains contextes (10)\n",
    "- Certains tags seront quasiement introuvable pour certaines situations. Il faudra habilement choisir une fonction de score (tous les exemples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que beaucoup de targets ont des version (ex: \"c++-32\") associées à leur nom. J'ai bien peur que le fait que la version soit présente brouille la prédiction.\n",
    "\n",
    "On se rappellera d'un possible traitement à effectuer par la suite. Je suppose naivement que l'on ne souhaite pas forcément prédire la version spécifique en fonction d'une question mais plutôt juste le tag initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itération 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine étape serait de s'intéresser à la balise code afin de rajouter de l'information.\n",
    "En effet, comme on l'a vu précédemment, certaines questions on vu la majorité de contenu se faire supprimer car la majorité était du code.\n",
    "\n",
    "On peut commencer par essayer, en fonction de la balise de code, de détecter le language qui y est présent.\n",
    "\n",
    "Après expérimentation avec les packages [guesslang](https://github.com/yoeo/guesslang) / [whats_that_code](https://github.com/matthewdeanmartin/whats_that_code) c'était très difficile. Le seule package qui m'apporte un peu d'espoir est [pygments](https://github.com/pygments/pygments) mais il a parfois de mauvaises prédictions.\n",
    "\n",
    "Je propose malgré tout de l'utiliser et de voir ce que cela donne.\n",
    "\n",
    "On va donc simplement remplacer la balise de code par le nom du langage détecté pour chaque morceaux de code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après ce que je vois, ce n'est pas fameux.\n",
    "\n",
    "Supprimons les lettres uniques et la négation pour le moment sans enlever la lettre C qui correspond au langage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je me dis qu'on peut certainement conserver la balise code ainsi que son contenu et espère que notre IA se rende compte que certains mots clés appartiennent à un langage spécifique (ex: \"def\" en python).\n",
    "\n",
    "Il y aura certainement encore des traitements à faire car dans le code il peut se passer plein de choses => Commentaires / Caractères spéciaux etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion :\n",
    "\n",
    "J'avais donc déjà testé cela avec mon système de version.\n",
    "\n",
    "J'ai décidé de ne pas continuer avec cette approche car elle était trop instable. Je n'étais également pas très à l'aise avec le fait de rajouter manuellement ce que le modèle pensait être le langage à la fin de texte. Les prédictions n'étaient également pas forcément tout le temps bonnes et il n'est pas forcément tout le temps question de langage de programmation mais par exemple de technologies / librairies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itération 3\n",
    "\n",
    "On va dans cette partie s'intéresser aux targets. En effet cette dernière possède parfois des détails peu pertinents comme par exemple des versions trop spécifiques.\n",
    "\n",
    "Il faut également formatter la target pour qu'elle fonctionne bien avec le reste du code. Certains modèles prennent en entrée des caractères limités. Par exemple sans le caractère '+' présent dans 'c++'. Il faut donc encoder ce string en 'cpp' par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En faisant mes recherches j'ai trouvé ce string correspondant aux target à l'intérieur de mon csv :\n",
    "\n",
    "`<android><android-mediaplayer><audio-player><monkey><android-monkey><android-music-player>`\n",
    "\n",
    "On peut voir qu'il y a 6 targets au lieux de 5. J'ai donc traiter ce cas en limitant à 5 targets tout simplement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons quelques données pour voir si on peut traiter certains cas absurdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va également les trier par ordre de fréquence. Target 1 aura la target la plus fréquente et target 5 la moins fréquente de notre distribution de targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
